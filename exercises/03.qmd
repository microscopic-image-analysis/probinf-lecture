---
jupyter: python3
title: Exercise 3
---

# Problem 1: Sampling from the 3D unit ball

Sample uniformly from the 3D unit ball $\mathbb{B}^3 := \{\mathbf{x} \in \mathbb{R}^3 \quad | \quad \|\mathbf{x}\| \leq 1\}$ in serveral different ways

## a):

Using rejection sampling.

> **What would be a convenient proposal distribution?**

We use the uniform distribution on the cube $[-1, 1]^3$, since it's easy to sample from.

> **Write a rejection sampler and visualize the samples.**

```{python}
%matplotlib widget

import numpy as np
import matplotlib.pyplot as plt

def sample_ball(N, rng=None):
    """
    sample `N` samples from the 3-dimensional unit ball
    """
    rng = rng or np.random.default_rng()
    i = 0
    samples = np.empty((N, 3))

    while i < N:
        x, y, z = rng.normal(size=3)
        if x**2 + y**2 + z**2 > 1:
            # reject
            continue
        # accept
        samples[i, :] = (x, y, z)
        i += 1
    return samples

samples = sample_ball(500)

fig = plt.figure()
ax = fig.add_subplot(projection="3d")
ax.set_aspect("equal")
ax.scatter(samples[:, 0], samples[:, 1], samples[:, 2])
```


> **Write down the PDF of the target distribution $p$ (i.e. the uniform distribution over $\mathbb{B}^3$) as well as your proposal distribution $q$ in terms of the (cartesian) coordinates $x, y, z$.**

$$
\begin{aligned}
f_p(x, y, z) &= \frac{3}{4 \pi} \mathbb 1(x^2 + y^2 + z^2 < 1) \\
f_q(x, y, z) &= \frac{1}{8} \mathbb 1(-1 < x < 1) \cdot \mathbb 1(-1 < y < 1) \cdot \mathbb 1(-1 < z < 1) \\
\end{aligned}
$$

Note that unlike $f_q(x, y, z)$, $f_p(x, y, z)$ does *not* factorize into three individual functions $g(x) h(y) j(z)$.

> **If you interpret the coordinates as random variables, are they independent under $p$? And under $q$?**

$f_q$ factorizes into three functions in $x, y, z$ respectively and thus the three RVs are independent.

$f_p$ does not factorize and the RVs are *not* independent. Compare for example the marginal distribution of $X$ and $Z$ to the conditional distribution of $X$ and $Z$ for $Y = 1$.

## b):

### i):

Can we sample directly from the unit ball?
Use spherical coordinates $r \in [0, \infty)$, $\varphi \in [0, 2\pi)$, $\theta \in [0, \pi]$ that are related to the cartesian coordinates $x$, $y$, $z$ via:
$$
\begin{aligned}
    x &= r \sin \theta \cos \varphi \\
    y &= r \sin \theta \sin \varphi \\
    z &= r \cos \theta
\end{aligned}
$$ 

![Spherical and Cartesian Coordinates](images/3D_Spherical.png){width=300}

> **Sample $r$, $\varphi$, $\theta$ uniformly from the right intervals, so that all points lie within $\mathbb{B}^3$. What do you observe?**

If we choose
$$
\begin{aligned}
r &\in [0, 1] \\
\varphi &\in [0, 2\pi) \\
\theta &\in [0, \pi]
\end{aligned}
$$

then all points lie within $\mathbb B^3$

```{python}
def rpt_to_xyz(r, phi, theta):
    x = r * np.sin(theta) * np.cos(phi)
    y = r * np.sin(theta) * np.sin(phi)
    z = r * np.cos(theta)
    return x, y, z

def sample_spherical(N, rng=None):
    rng = rng or np.random.default_rng()

    samples = np.empty((N, 3))
    for i in range(N):
        r = rng.uniform(0, 1)
        phi = rng.uniform(0, 2*np.pi)
        theta = rng.uniform(0, np.pi)
        samples[i, :] = rpt_to_xyz(r, phi, theta)
    return samples

samples = sample_spherical(500)
fig = plt.figure()
ax = fig.add_subplot(projection="3d")
ax.set_aspect("equal")
ax.scatter(samples[:, 0], samples[:, 1], samples[:, 2])
```


### ii):

> **What distribution do we need to sample $(r, \varphi, \theta)$ from, to obtain uniform samples from $\mathbb{B}^3$?**
> **Hint: Express the PDF of $p$ from a) in terms of $r, \varphi$ and $\theta$.**

To express the PDF of $p$ (which we wrote in terms of $x, y, z$) in terms of $r, \varphi, \theta$, we need to apply the change of variables theorem:

$$
f_p^\circ\bigl(r, \varphi, \theta\bigr) =  \Biggl|\underbrace{\frac{\partial(x, y, z)}{\partial(r, \varphi, \theta)}}_J\Biggr| f_p\bigl(x(r, \varphi, \theta), y(r, \varphi, \theta), z(r, \varphi, \theta)\bigr)
$$
where $|J|$ is the determinant of the Jacobi matrix, and $f_p^\circ(\cdot)$ and $f_p(\cdot)$ are the PDF in spherical- and cartesian coordinates respectively. 

Given the above definition of the spherical coordinates, the Jacobi matrix can be readily evaluated:
$$
J = \frac{\partial(x, y, z)}{\partial(r, \varphi, \theta)} = \begin{pmatrix}
    \sin\theta \cos\varphi & r \cos\theta \cos\varphi & - r \sin\theta \sin\varphi \\
    \sin\theta \sin\varphi & r \cos\theta \sin\varphi & r \sin\theta \cos\varphi \\
    \cos\theta & -r \sin\varphi & 0
\end{pmatrix}
$$

and thus

$$
\begin{aligned}
\det(J) &= r^2 (\cos^2\theta \cos^2\varphi \sin\theta + \sin^3\theta \sin^2\varphi + \cos^2\theta \sin^2\varphi \sin\theta + \sin^3\theta \cos^2\varphi) \\
&= r^2 \sin\theta (\cos^2\theta \cos^2\varphi + \sin^2\theta \sin^2\varphi + \cos^2\theta \sin^2\varphi + \sin^2\theta \cos^2\varphi) \\
&= r^2 \sin\theta (\cos^2\theta \cdot \underbrace{[\cos^2\varphi + \sin^2\varphi]}_{= 1} + \sin^2\theta \cdot \underbrace{[\sin^2\varphi + \cos^2\varphi]}_{= 1}) \\
&= r^2 \sin\theta (\cos^2\theta + \sin^2\theta) \\
&= r^2 \sin\theta 
\end{aligned}
$$

and $f_p$ actually has a quite simple form in spherical coordinates:

$$
f_p\bigl(x(r, \varphi, \theta), y(r, \varphi, \theta), z(r, \varphi, \theta)\bigr) = \frac{3}{4 \pi} \mathbb 1(r \leq 1)
$$

and therefore

$$
f_p^\circ\bigl(r, \varphi, \theta\bigr) = \frac{3}{4 \pi} r^2 \sin\theta \, \mathbb 1(r \leq 1)
$$

> **If you interpret the *spherical* coordinates as random variables, are they independent under $p$?**

The PDF factorizes into
$$
f_p^\circ\bigl(r, \varphi, \theta\bigr) = \frac{1}{2 \pi} g(r) h(\theta)
$$
with
$$
\begin{aligned}
g(r) &:= 3 r^2 \\
h(\theta) &:= \frac{1}{2} \sin\theta
\end{aligned}
$$
i.e. a product of individual distributions. The random variables corresponding to the individual coordinates $r, \varphi, \theta$ are thus independent, and we can easily sample from $f_p^\circ$ by sampling $\varphi$ uniformly and $r$ and $\theta$ via the inversion method.
$$
\begin{aligned}
G(r) &:= \int_0^r g(r') dr' = r^3 \quad \Rightarrow G^{-1}(u) = u^{1/3}\\
H(\theta) &:= \int_0^\theta h(\theta') d\theta' = \frac{1 - \cos\theta}{2} \quad \Rightarrow H^{-1}(v) = \arccos(-2v + 1)
\end{aligned}
$$

```{python}
def sample_spherical_correct(N, rng=None):
    rng = rng or np.random.default_rng()

    samples = np.empty((N, 3))
    for i in range(N):
        r = rng.uniform(0, 1)**(1 / 3)  # inverse transform for r
        phi = rng.uniform(0, 2*np.pi)  # uniform sampling for phi
        theta = np.arccos(-2 * rng.uniform(0, 1) + 1)  # inverse transform for theta
        samples[i, :] = rpt_to_xyz(r, phi, theta)
    return samples

samples = sample_spherical_correct(500)
fig = plt.figure()
ax = fig.add_subplot(projection="3d")
ax.set_aspect("equal")
ax.scatter(samples[:, 0], samples[:, 1], samples[:, 2])
```


## c)

As shown in the lecture, you can sample from the unit $n$-ball by first sampling from the unit $n-1$-sphere (which gives you $n$-dimensional points $x_i$ all with length $\|x_i\| = 1$), and then re-scaling these points with a random length $r$ whose PDF is $f(r) = n r^{n-1}$.

> **Implement sampling from the $n-1$-sphere. Then use the method to sample from the 3D unit ball.**

```{python}
def sample_n_sphere(n, N, rng=None):
    """
    sample N points from the unit n-sphere

    parameters
    ----------
    n: defines the n-sphere
    N: number of samples to draw
    """
    rng = rng or np.random.default_rng()

    x = rng.normal(size=(n + 1, N))
    x /= np.linalg.norm(x, axis=0)
    return x

def sample_n_ball(n, N, rng=None):
    """
    sample N points from the unit n-ball

    parameters
    ----------
    n: defines the n-ball
    N: number of samples to draw
    """
    rng = rng or np.random.default_rng()

    x = sample_n_sphere(n - 1, N, rng)  # sample from n-1-sphere
    r = np.power(rng.uniform(0, 1, size=N), 1 / n)  # inversion method for r
    return x * r

samples = sample_n_ball(3, 500)
fig = plt.figure()
ax = fig.add_subplot(projection="3d")
ax.set_aspect("equal")
ax.scatter(samples[0, :], samples[1, :], samples[2, :])
```


## d)

Use the method from **c)** to sample 500 points from the $5-1$-sphere.
Project all points down to their first 3 coordinates (resulting in 500 points in 3D).

> **Make a 3D scatter plot of these points. How are they distributed?**

```{python}
samples = sample_n_sphere(4, 500)
samples = samples[0:3, :]
fig = plt.figure()
ax = fig.add_subplot(projection="3d")
ax.set_aspect("equal")
ax.scatter(samples[0, :], samples[1, :], samples[2, :])
```

The samples are distributed uniformly inside $\mathbb B^3$!
For a proof see [this reference (link to .pdf)](http://compneuro.uwaterloo.ca/files/publications/voelker.2017.pdf)


# Problem 2: The Ziggurat algorithm

![Model of the [Chogha Zanbil](https://en.wikipedia.org/wiki/Chogha_Zanbil), an example of a [Ziggurat](https://en.wikipedia.org/wiki/Ziggurat)](images/Chogha_Zanbil_Ziggurat_(model).jpg){width=300}

The [Ziggurat algorithm](https://en.wikipedia.org/wiki/Ziggurat_algorithm) is a rejection sampling method to draw random numbers from distributions whose PDF is *monotonically decreasing* (e.g. Exponential distribution, Half-normal distribution, ...). 

## a)

> **Taking inspiration from the name alone, can you sketch a rejection-sampling method that samples from the exponential distribution?**

```{python}
from scipy.optimize import root_scalar
from matplotlib.patches import Rectangle


def make_table(N, x1):
    """
    Tabulate the upper right corners of the N+1 rectangles, given the x-corrdinate of
    the first rectangle's corner.
    Note that the last rectangle has zero area (x=0, y=1)
    """
    y0 = 0.0
    y1 = t = np.exp(-x1)  # tail mass (area under PDF for x > x1)
    A = x1 * y1 + t
    x0 = A / y1
    y = [y0, y1]
    x = [x0, x1]
    for i in range(N - 1):
        yi = y[-1] + A / np.abs(x[-1])
        xi = -np.log(yi)
        x.append(xi)
        y.append(yi)
    return np.array(x), np.array(y)


def yn_error_given_x1(x1, N=256):
    yn = make_table(N, x1)[1][-1]
    # we expect the last y to be at f(x=0) = 1
    return yn - 1


def draw_ziggurat(N):
    root_result = root_scalar(lambda x1: yn_error_given_x1(x1, N), bracket=[1e-5, 10])
    x1 = root_result.root
    x, y = make_table(N, x1)
    fig, ax = plt.subplots(1)
    for i in range(N):
        height = y[i + 1] - y[i]
        width = x[i]
        ax.add_patch(
            Rectangle(
                (0.0, y[i]),
                width,
                height,
                edgecolor="black"
            ),
        )
    x_plt = np.linspace(0, 9, 100)
    ax.plot(x_plt, np.exp(-x_plt), color="red")
    x_plt = np.linspace(x[1], x[0], 20)
    y_lo = np.exp(-x_plt)
    y_hi = y[1] * np.ones_like(y_lo)
    ax.fill_between(x_plt, y_lo, y_hi, color="green")
    x_plt = np.linspace(x[0], 9, 50)
    y_hi = np.exp(-x_plt)
    ax.fill_between(x_plt, y_hi, color="orange")


draw_ziggurat(5)
```

## b)

> **Implement the Ziggurat method for the standard Exponential distribution**

```{python}
class ZigguratExp:
    def __init__(self, N=256, rng=None):
        root_result = root_scalar(lambda x1: yn_error_given_x1(x1, N), bracket=[1e-5, 10])
        x1 = root_result.root
        self.N = N
        self.x, self.y = make_table(N, x1)
        self.rng = rng or np.random.default_rng()

    def sample(self):
        i = self.rng.integers(0, self.N)
        x = self.x[i] * self.rng.uniform()
        if x < self.x[i + 1]:
            return x
        if i == 0:
            return self.x[1] + self.sample()
        # rare slow case from here on
        y = self.y[i] + self.rng.uniform() * (self.y[i + 1] - self.y[i])
        if y < np.exp(-x):
            # accept
            return x
        # reject
        return self.sample()
```

```{python}
sampler = ZigguratExp()
x = [sampler.sample() for _ in range(1_000_000)]
fig, ax = plt.subplots(1)
ax.hist(x, bins=20, range=(0, 8), density=True)
x_plt = np.linspace(0, 8, 100)
ax.plot(x_plt, np.exp(-x_plt), color="red")
ax.set_yscale("log")
```




Bonus: Can you find a way so your method only uses a single 64 bit random integer as input *most of the time*?

::: {.callout-tip}
In newer `numpy` versions (`>= 1.17.0`), the Ziggurat method is the default method for generating normal-, exponential- or gamma-distributed random samples.
Before that, the [Box Muller method](https://en.wikipedia.org/wiki/Box%E2%80%93Muller_transform) was used, which can still be accessed via the [legacy](https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState) `np.random.RandomState` class.
:::